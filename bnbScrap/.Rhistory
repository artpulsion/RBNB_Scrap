# get the id
id.houses.class <- "._1rp5252"
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
# get the price
price.houses.class <- "._hylizj6"
price.pattern <- 'Preço'
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)] %>% gsub(price.pattern, "", .)
# append the ids, prices and timeframes
ids.houses <- c(ids.houses, current.id.houses)
prices.houses <- c(prices.houses, current.price.houses)
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
cat("Initial page -- \n")
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
############################################
#
# OTHERS PAGE
#
############################################
for (index.page in 1L:(nbr.pages-1)) {
# construct the url for the next webpage to scrap
current.url <- paste0("https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=YYFR8cTp&section_offset=", index.page)
# get the current timestamps
timestamps <- Sys.time()
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
# get the informations related to the ids houses and append it into the base
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
ids.houses <- c(ids.houses, current.id.houses)
# get the informations related to the prices houses and append it into the base
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
cat(sprintf('fukit: %d', length(current.price.houses)))
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)] %>% gsub(price.pattern, "", .)
prices.houses <- c(prices.houses, current.price.houses)
# construct the timestamps
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
# advertize about the current pagination
cat(sprintf("Current page: %d \n", index.page + 1))
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
}
# build an object to return the whole informations and return it
infos.city <- list( 'ids.city' = ids.houses,
'price.city' = prices.houses,
'timeframes.request' = timeframes )
return(infos.city)
}
library(bnbScrap)
devtools::load_all()
tmp<-bnbScrap:::getInfosCity()
# construct the url for the next webpage to scrap
current.url <- paste0("https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=YYFR8cTp&section_offset=", index.page)
# get the current timestamps
timestamps <- Sys.time()
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
index.page<-2
# construct the url for the next webpage to scrap
current.url <- paste0("https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=YYFR8cTp&section_offset=", index.page)
# get the current timestamps
timestamps <- Sys.time()
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
# get the informations related to the ids houses and append it into the base
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
# get the id
id.houses.class <- "._1rp5252"
# get the price
price.houses.class <- "._hylizj6"
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
# get the informations related to the ids houses and append it into the base
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
ids.houses <- c(ids.houses, current.id.houses)
# get the informations related to the prices houses and append it into the base
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses
current.price.houses2 <- current.price.houses[grepl(price.pattern, current.price.houses)]
price.pattern <- 'Preço'
current.price.houses2 <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses2
current.price.houses2 <- current.price.houses[grepl(price.pattern, current.price.houses)]%>% gsub(price.pattern, "", .)
current.price.houses2
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
current.price.houses <- current.price.houses %>% gsub(price.pattern, "", current.price.houses)
library(bnbScrap)
library(bnbScrap)
devtools::load_all()
tnp<-bnbScrap::getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- current.price.houses %>% gsub(current.price.houses, price.pattern, "")
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
current.price.houses <- current.price.houses %>% gsub(current.price.houses, price.pattern, "")
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
current.price.houses <- gsub(current.price.houses, price.pattern, "")
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
current.price.houses
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
# get the informations related to the prices houses and append it into the base
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the url for the first page of the current city
url_city <- "https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=qqjUJxeE"
# structure containers
timeframes <- c()
ids.houses <- c()
prices.houses <- c()
# read the page
webpage.url <- read_html(url_city)
# get the timestamp
timestamps <- Sys.time()
# get the number of pages
nbr.pages.class <- "._1am0dt"
nbr.pages.str <- webpage.url %>% html_nodes(nbr.pages.class) %>% html_text() %>% as.integer() %<>% na.omit
nbr.pages <- max(nbr.pages.str)
# get the id
id.houses.class <- "._1rp5252"
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
# get the price
price.houses.class <- "._hylizj6"
price.pattern <- 'Preço'
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
# append the ids, prices and timeframes
ids.houses <- c(ids.houses, current.id.houses)
prices.houses <- c(prices.houses, current.price.houses)
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
current.price.houses
# remove warnings
#options(warn=-1)
############################################
#
# INITIAL PAGE
#
############################################
# get the url for the first page of the current city
url_city <- "https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=qqjUJxeE"
# structure containers
timeframes <- c()
ids.houses <- c()
prices.houses <- c()
# read the page
webpage.url <- read_html(url_city)
# get the timestamp
timestamps <- Sys.time()
# get the number of pages
nbr.pages.class <- "._1am0dt"
nbr.pages.str <- webpage.url %>% html_nodes(nbr.pages.class) %>% html_text() %>% as.integer() %<>% na.omit
nbr.pages <- max(nbr.pages.str)
# get the id
id.houses.class <- "._1rp5252"
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
# get the price
price.houses.class <- "._hylizj6"
price.pattern <- 'Preço'
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
# append the ids, prices and timeframes
ids.houses <- c(ids.houses, current.id.houses)
prices.houses <- c(prices.houses, current.price.houses)
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
cat("Initial page -- \n")
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
for (index.page in 1L:(nbr.pages-1)) {
# construct the url for the next webpage to scrap
current.url <- paste0("https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=YYFR8cTp&section_offset=", index.page)
# get the current timestamps
timestamps <- Sys.time()
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
# get the informations related to the ids houses and append it into the base
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
ids.houses <- c(ids.houses, current.id.houses)
# get the informations related to the prices houses and append it into the base
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
cat(sprintf('fukit: %d', length(current.price.houses)))
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
prices.houses <- c(prices.houses, current.price.houses)
# construct the timestamps
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
# advertize about the current pagination
cat(sprintf("Current page: %d \n", index.page + 1))
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
}
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
library(bnbScrap)
bnbScrap:::getInfosCity
bnbScrap:::getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
library(bnbScrap)
devtools::load_all()
bnbScrap::getInfosCity()
Sys.getlocale()
Sys.setlocale("LC_TIME", "de_DE.utf8")   # Modern Linux etc.
library(bnbScrap)
bnbScrap::getInfosCity()
bnbScrap:::getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
getInfosCity <- function() {
# remove warnings
options(warn=-1)
Sys.setlocale("LC_ALL","French")
############################################
#
# INITIAL PAGE
#
############################################
# get the url for the first page of the current city
url_city <- "https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=qqjUJxeE"
# structure containers
timeframes <- c()
ids.houses <- c()
prices.houses <- c()
# read the page
webpage.url <- read_html(url_city)
# get the timestamp
timestamps <- Sys.time()
# get the number of pages
nbr.pages.class <- "._1am0dt"
nbr.pages.str <- webpage.url %>% html_nodes(nbr.pages.class) %>% html_text() %>% as.integer() %<>% na.omit
nbr.pages <- max(nbr.pages.str)
# get the id
id.houses.class <- "._1rp5252"
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
# get the price
price.houses.class <- "._hylizj6"
price.pattern <- 'Preço'
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
# append the ids, prices and timeframes
ids.houses <- c(ids.houses, current.id.houses)
prices.houses <- c(prices.houses, current.price.houses)
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
cat("Initial page -- \n")
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
############################################
#
# OTHERS PAGE
#
############################################
for (index.page in 1L:(nbr.pages-1)) {
# construct the url for the next webpage to scrap
current.url <- paste0("https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=YYFR8cTp&section_offset=", index.page)
# get the current timestamps
timestamps <- Sys.time()
# Fetch the web page based on the url
webpage.url <- read_html(current.url)
# get the informations related to the ids houses and append it into the base
current.id.houses <- webpage.url %>% html_nodes(id.houses.class) %>% html_attr("id")
ids.houses <- c(ids.houses, current.id.houses)
# get the informations related to the prices houses and append it into the base
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
cat(sprintf('fukit: %d \n', length(current.price.houses)))
cat(price.pattern)
cat(current.price.houses)
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
prices.houses <- c(prices.houses, current.price.houses)
# construct the timestamps
timeframes <- c(timeframes, rep(timestamps, length(current.id.houses)))
# advertize about the current pagination
cat(sprintf("Current page: %d \n", index.page + 1))
cat(sprintf("Number of houses: %d \n", length(current.id.houses)))
cat(sprintf("Number of prices %d \n \n", length(current.price.houses) ))
}
# build an object to return the whole informations and return it
infos.city <- list( 'ids.city' = ids.houses,
'price.city' = prices.houses,
'timeframes.request' = timeframes )
return(infos.city)
}
Sys.getlocale()
Sys.setlocale("LC_ALL","French")
Sys.getlocale()
library(bnbScrap)
bnbScrap:::getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
price.pattern <- '€'
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
library(bnbScrap)
bnbScrap:::getInfosCity
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
Sys.getlocale(category="LC_ALL")
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
library(bnbScrap)
bnbScrap:::getInfosCity
bnbScrap:::getInfosCity()
tmp <- bnbScrap:::getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
library(bnbScrap)
devtools::load_all()
library(bnbScrap)
tmp<-bnbScrap:::getInfosCity()
View(tmp)
tmp[["ids.houses"]]
View(tmp)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
bnbScrap:::getInfosCity
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
library(bnbScrap)
bnbScrap:::getInfosCity
bnbScrap:::getInfosCity()
View(infos.city)
infos.city[["price.city"]]
infos.city$prices.city
current.price.houses <- gsub( pattern = 'ço', replacement = "", x = infos.city$prices.city)
current.price.houses
current.price.houses <- gsub( pattern = c('ço', '€'), replacement = "", x = infos.city$prices.city)
current.price.houses
current.price.houses <- gsub( pattern = c('ço'), replacement = "", x = infos.city$prices.city)
current.price.houses2 <- gsub( pattern = "€", replacement = "", x = current.price.houses)
current.price.houses2
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# rework the prices
prices.houses <- gsub(pattern = 'ço', replacement = "", x = prices.houses)
library(bnbScrap)
bnbScrap:::getInfosCity()
bnbScrap:::getInfosCity()
View(infos.city)
infos.city$prices.city
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
infos.city$prices.city
infos.city$prices.city %>% as.integer()
prices.houses <- gsub(pattern = 'ço', replacement = "", x = infos.city$prices.city)
prices.houses
prices.houses %<>% as.integer
prices.houses
prices.houses <- gsub(pattern = 'ço', replacement = "", x = infos.city$prices.city)
prices.houses
prices.houses <- gsub(pattern = '€', replacement = "", x = prices.houses)
prices.houses
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "_1m8bb6v"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
# get the url for the first page of the current city
url_city <- "https://www.airbnb.pt/s/Porto--Portugal/homes?query=Porto%2C%20Portugal&refinement_paths%5B%5D=%2Fhomes&allow_override%5B%5D=&place_id=ChIJwVPhxKtlJA0RvBSxQFbZSKY&tab_id=all_tab&s_tag=qqjUJxeE"
# structure containers
timeframes <- c()
ids.houses <- c()
prices.houses <- c()
# read the page
webpage.url <- read_html(url_city)
# get the timestamp
timestamps <- Sys.time()
# get the price
price.houses.class <- "_1m8bb6v"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._1m8bb6v"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)
View(current.price.houses)
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)%>% html_text()
current.price.houses
# get the price
price.houses.class <- "._1m8bb6v"
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._1m8bb6v"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)%>% html_text()
current.price.houses
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._1m8bb6v"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)
current.price.houses
current.price.houses[[1]]
current.price.houses[1]
current.price.houses[5]
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._hylizj6"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class)
current.price.houses
current.price.houses[[1]]
current.price.houses[1]
current.price.houses[1][1]
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_attr("span")
current.price.houses
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._hylizj6"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._1m8bb6v"
price.pattern <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
price.patterns <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._hylizj6"
price.patterns <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses
# get the price
price.houses.class <- "._hylizj6"
price.patterns <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- current.price.houses[grepl(price.pattern, current.price.houses)]
current.price.houses <- gsub( pattern = price.pattern, replacement = "", x = current.price.houses)
price.patterns <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")
library(stringr)
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
as.numeric(str_extract_all(current.price.houses, "[0-9]+))
)
)
as.numeric(str_extract_all(current.price.houses, "[0-9]+"))
current.price.houses <- as.numeric(str_extract_all(current.price.houses, "[0-9]+"))
current.price.houses <- as.numeric(str_extract_all(current.price.houses, "[0-9]+")) %>% na.omit
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._hylizj6"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses %<>% as.numeric(str_extract_all(current.price.houses, "[0-9]+")) %>% na.omit
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
# get the price
price.houses.class <- "._hylizj6"
current.price.houses <- webpage.url %>% html_nodes(price.houses.class) %>% html_text()
current.price.houses <- as.numeric(str_extract_all(current.price.houses, "[0-9]+")) %>% na.omit
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R', encoding = 'UTF-8')
library(bnbScrap)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
View(infos.city)
infos.city$prices.city
library(bnbScrap)
bnbScrap:::getInfosCity()
infos.city
hist(infos.city$prices.city)
hist(infos.city$prices.city, breaks = 20)
hist(infos.city$prices.city, breaks = 50)
infos.city
as.data.frame(infos.city)
a<-as.data.frame(infos.city)
View(a)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
library(bnbScrap)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity()
getInfosCity(tf.df = TRUE)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity(tf.df = TRUE)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
View(infos.city)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity(tf.df = T)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
View(infos.city)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
getInfosCity(tf.df = T)
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
source('C:/Users/sofianembarki/Desktop/bnbScrap/R/getInfosCity.R')
a<-getInfosCity(tf.df = T)
View(a)
View(a)
hist(a)
hist(a$prices_houses)
